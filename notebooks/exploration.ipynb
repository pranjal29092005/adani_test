{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "433677ea",
   "metadata": {},
   "source": [
    "## üì¶ Installation (Run This First)\n",
    "\n",
    "**Important:** Run this cell first to install all required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c028f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# INSTALL REQUIRED LIBRARIES\n",
    "# ===================================================================\n",
    "# WHY: Ensures all dependencies are available before running analysis\n",
    "#      This cell installs packages if they're not already installed\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    'pandas>=2.0.0',\n",
    "    'numpy>=1.24.0',\n",
    "    'matplotlib>=3.7.0',\n",
    "    'seaborn>=0.12.0',\n",
    "    'scikit-learn>=1.3.0',\n",
    "    'openpyxl>=3.0.0'  # For reading Excel files\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        install_package(package)\n",
    "        print(f\"‚úì {package.split('>=')[0]} installed/verified\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to install {package}: {e}\")\n",
    "\n",
    "print(\"\\n‚úì All packages ready!\")\n",
    "print(\"You can now run the rest of the notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f69234",
   "metadata": {},
   "source": [
    "# Adani AI Labs ‚Äì Energy Consumption Forecasting\n",
    "## Exploratory Data Analysis & Model Development\n",
    "\n",
    "**Objective:** Understand the data characteristics, patterns, and build a robust forecasting model.\n",
    "\n",
    "**Approach:** Classical ML with time-aware best practices\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a4c90c",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 1: Import Essential Libraries\n",
    "# ===================================================================\n",
    "# WHY: We need data manipulation, numerical computation, and visualization tools\n",
    "#      for exploratory data analysis (EDA) of time-series energy data.\n",
    "\n",
    "# Core data manipulation libraries\n",
    "import pandas as pd          # For time-series data handling and analysis\n",
    "                             # WHY: Best tool for datetime indexing and tabular data\n",
    "import numpy as np           # For numerical operations and array computations\n",
    "                             # WHY: Efficient mathematical operations on large datasets\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt  # For creating plots and charts\n",
    "                                 # WHY: Standard plotting library with full customization\n",
    "import seaborn as sns            # For statistical visualizations\n",
    "                                 # WHY: Beautiful, high-level statistical plots\n",
    "\n",
    "# Utility libraries\n",
    "from pathlib import Path     # For cross-platform file path handling\n",
    "                             # WHY: Works on Windows, Linux, macOS without modification\n",
    "import warnings              # For suppressing non-critical warnings\n",
    "                             # WHY: Keeps output clean and focused on results\n",
    "\n",
    "# ===================================================================\n",
    "# CONFIGURATION SETTINGS\n",
    "# ===================================================================\n",
    "# Suppress warnings to keep output clean\n",
    "# WHY: FutureWarnings and DeprecationWarnings don't affect our analysis\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set professional plotting style\n",
    "# WHY: 'seaborn-v0_8-darkgrid' provides clean, publication-quality visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Use color palette optimized for distinguishing multiple categories\n",
    "# WHY: 'husl' palette ensures colors are perceptually distinct\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure pandas display settings for better data visibility\n",
    "# WHY: Show all columns without truncation during exploration\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.max_rows', 100)      # Display up to 100 rows\n",
    "\n",
    "print(\"‚úì All imports successful\")\n",
    "print(\"‚úì Environment configured for time-series analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199a74c7",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a90476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 2: Load Raw Energy Consumption Data\n",
    "# ===================================================================\n",
    "# WHY: Before any analysis, we must load the dataset and verify its integrity.\n",
    "#      This step ensures the data file exists and is readable.\n",
    "\n",
    "# Define the path to the CSV data file\n",
    "# WHY: Using Path() instead of strings ensures cross-platform compatibility\n",
    "data_path = Path(\"../data/energy_consumption_raw.csv\")\n",
    "\n",
    "# Check if the file exists before attempting to load\n",
    "# WHY: Prevents cryptic errors and provides clear feedback to the user\n",
    "if not data_path.exists():\n",
    "    print(f\"‚ùå Data file not found at {data_path}\")\n",
    "    print(\"Please ensure the file is in the correct location.\")\n",
    "else:\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    # WHY: read_csv() intelligently parses CSV files and infers data types\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # Display summary statistics about the loaded data\n",
    "    print(f\"‚úì Data loaded successfully: {len(df):,} records\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    # WHY: Immediate feedback confirms successful loading and shows data dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278f888",
   "metadata": {},
   "source": [
    "## 3. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496cd661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 3A: Inspect First and Last Rows\n",
    "# ===================================================================\n",
    "# WHY: Viewing the beginning and end of the dataset helps us:\n",
    "#      1. Understand the data structure and column names\n",
    "#      2. Verify the time range of the data\n",
    "#      3. Spot any obvious formatting issues\n",
    "\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())  # WHY: Shows the earliest records in chronological order\n",
    "\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(df.tail())  # WHY: Shows the most recent records\n",
    "\n",
    "print(\"\\nData Info:\")\n",
    "df.info()  # WHY: Displays column types, non-null counts, and memory usage\n",
    "           # This is CRITICAL for identifying missing values and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 3B: Statistical Summary\n",
    "# ===================================================================\n",
    "# WHY: describe() provides key statistics (mean, std, min, max, quartiles)\n",
    "#      This helps us understand the distribution and range of values\n",
    "\n",
    "print(\"Statistical Summary:\")\n",
    "display(df.describe())\n",
    "# WHY: Identifies outliers, typical ranges, and data variability\n",
    "#      Essential for understanding what \"normal\" energy consumption looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 3C: Check for Missing Values\n",
    "# ===================================================================\n",
    "# WHY: Missing data can break models and bias analysis\n",
    "#      We must identify and handle missing values appropriately\n",
    "\n",
    "missing = df.isnull().sum()  # Count missing values per column\n",
    "print(\"Missing Values:\")\n",
    "print(missing)\n",
    "print(f\"\\nTotal missing: {missing.sum()}\")\n",
    "\n",
    "# WHY: Time-series models require complete data for lag features\n",
    "#      Missing values must be imputed using domain-appropriate methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fca9f3",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 4: Data Preprocessing (Time-Series Specific)\n",
    "# ===================================================================\n",
    "# WHY: Time-series data requires special handling to preserve temporal order\n",
    "#      and enable datetime-based operations (resampling, grouping, etc.)\n",
    "\n",
    "df_clean = df.copy()  # Create a copy to preserve original data\n",
    "                       # WHY: Good practice to keep raw data unchanged\n",
    "\n",
    "# Convert first column to datetime format\n",
    "# WHY: Pandas datetime objects enable time-based indexing and operations\n",
    "df_clean.iloc[:, 0] = pd.to_datetime(df_clean.iloc[:, 0])\n",
    "\n",
    "# Sort by time (CRITICAL for time-series)\n",
    "# WHY: Many time-series operations assume chronological order\n",
    "#      Lag features and rolling windows REQUIRE sorted data\n",
    "df_clean = df_clean.sort_values(df_clean.columns[0])\n",
    "\n",
    "# Set datetime as index\n",
    "# WHY: Datetime index enables .loc['2020-01-01'] style slicing\n",
    "#      Required for resampling and time-based operations\n",
    "df_clean = df_clean.set_index(df_clean.columns[0])\n",
    "\n",
    "# Handle missing values using forward-fill then backward-fill\n",
    "# WHY: Forward-fill is appropriate for continuous energy consumption\n",
    "#      (carries last known value forward, then backfills any remaining gaps)\n",
    "df_clean = df_clean.ffill().bfill()\n",
    "\n",
    "print(f\"‚úì Preprocessing complete\")\n",
    "print(f\"  Date range: {df_clean.index.min()} to {df_clean.index.max()}\")\n",
    "print(f\"  Total days: {(df_clean.index.max() - df_clean.index.min()).days}\")\n",
    "print(f\"  Frequency: {df_clean.index.to_series().diff().mode()[0]}\")\n",
    "# WHY: Frequency detection confirms hourly sampling (should be 1 hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1b3fe",
   "metadata": {},
   "source": [
    "## 5. Time Series Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 5A: Overall Time Series Visualization\n",
    "# ===================================================================\n",
    "# WHY: Visual inspection reveals trends, seasonality, and anomalies\n",
    "#      that are not obvious from statistics alone\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))  # Create large figure for clarity\n",
    "df_clean.plot(ax=ax, linewidth=0.8)       # Plot all data\n",
    "ax.set_title('Energy Consumption Over Time (Full Dataset)', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Energy Consumption', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)  # WHY: Grid helps read values from the plot\n",
    "plt.tight_layout()         # WHY: Prevents label overlap\n",
    "plt.show()\n",
    "\n",
    "# WHAT TO LOOK FOR:\n",
    "# - Long-term trends (increasing/decreasing consumption)\n",
    "# - Seasonal patterns (yearly cycles)\n",
    "# - Anomalies or sudden changes\n",
    "# - Overall stability of the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386532d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 5B: Zoomed View (First 30 Days)\n",
    "# ===================================================================\n",
    "# WHY: The full 6-year plot is compressed. Zooming in reveals finer patterns\n",
    "#      like daily cycles and hourly variations\n",
    "\n",
    "sample_month = df_clean.iloc[:24*30]  # First 720 hours (30 days)\n",
    "                                       # WHY: 24 hours/day √ó 30 days = representative sample\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "sample_month.plot(ax=ax, linewidth=1.2, color='darkblue')\n",
    "ax.set_title('Energy Consumption ‚Äì First 30 Days (Detailed View)', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Energy Consumption', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# WHAT TO LOOK FOR:\n",
    "# - Daily peaks and valleys (business hours vs. night)\n",
    "# - Weekly patterns (weekday vs. weekend)\n",
    "# - Consistency of patterns across days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61d171c",
   "metadata": {},
   "source": [
    "## 6. Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f64b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 6A: Extract Time Components for Pattern Analysis\n",
    "# ===================================================================\n",
    "# WHY: Energy consumption has different patterns based on:\n",
    "#      - Hour of day (business hours vs. night)\n",
    "#      - Day of week (weekday vs. weekend)\n",
    "#      - Month of year (seasonal effects)\n",
    "\n",
    "df_analysis = df_clean.copy()\n",
    "target_col = df_clean.columns[0]  # Get the energy consumption column name\n",
    "\n",
    "# Extract temporal features from the datetime index\n",
    "# WHY: These features will be used for aggregation and modeling\n",
    "df_analysis['hour'] = df_analysis.index.hour          # 0-23\n",
    "df_analysis['day_of_week'] = df_analysis.index.dayofweek  # Monday=0, Sunday=6\n",
    "df_analysis['month'] = df_analysis.index.month        # 1-12\n",
    "df_analysis['year'] = df_analysis.index.year          # For yearly trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7116843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 6B: Hourly Pattern Analysis\n",
    "# ===================================================================\n",
    "# WHY: Understanding hour-of-day patterns is CRITICAL for forecasting\n",
    "#      Energy consumption typically peaks during business hours (9 AM - 6 PM)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "# Calculate average consumption for each hour across all days\n",
    "# WHY: Aggregating by hour reveals the typical daily consumption profile\n",
    "hourly_avg = df_analysis.groupby('hour')[target_col].mean()\n",
    "\n",
    "hourly_avg.plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "ax.set_title('Average Energy Consumption by Hour of Day', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Hour', fontsize=12)\n",
    "ax.set_ylabel('Average Consumption', fontsize=12)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify peak and low consumption hours\n",
    "# WHY: These insights inform feature engineering and business decisions\n",
    "print(\"Peak hours:\", hourly_avg.nlargest(3).index.tolist())\n",
    "print(\"Low hours:\", hourly_avg.nsmallest(3).index.tolist())\n",
    "\n",
    "# KEY INSIGHTS: \n",
    "# - Peak hours indicate high demand periods (usually 9 AM - 6 PM)\n",
    "# - Low hours indicate low demand (usually 2 AM - 5 AM)\n",
    "# - This pattern will be captured by our 'hour' feature in modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8daa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 6C: Day-of-Week Pattern Analysis\n",
    "# ===================================================================\n",
    "# WHY: Energy consumption differs between weekdays and weekends\n",
    "#      Businesses operate differently on weekends, affecting demand\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Calculate average consumption for each day of the week\n",
    "# WHY: Reveals weekend vs. weekday consumption differences\n",
    "dow_avg = df_analysis.groupby('day_of_week')[target_col].mean()\n",
    "\n",
    "# Convert numeric day labels to readable names\n",
    "# WHY: Makes the plot easier to interpret for non-technical stakeholders\n",
    "dow_labels = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_avg.index = dow_labels\n",
    "\n",
    "dow_avg.plot(kind='bar', ax=ax, color='coral', edgecolor='black')\n",
    "ax.set_title('Average Energy Consumption by Day of Week', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Day', fontsize=12)\n",
    "ax.set_ylabel('Average Consumption', fontsize=12)\n",
    "ax.set_xticklabels(dow_labels, rotation=45)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# KEY INSIGHTS:\n",
    "# - Weekdays (Mon-Fri) typically show higher consumption (business activity)\n",
    "# - Weekends (Sat-Sun) typically show lower consumption\n",
    "# - This justifies our 'is_weekend' feature in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908af10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 6D: Monthly (Seasonal) Pattern Analysis\n",
    "# ===================================================================\n",
    "# WHY: Energy consumption varies by season (heating in winter, cooling in summer)\n",
    "#      This is especially true in regions with significant temperature variation\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "# Calculate average consumption for each month across all years\n",
    "# WHY: Reveals seasonal patterns (e.g., high consumption in summer/winter)\n",
    "monthly_avg = df_analysis.groupby('month')[target_col].mean()\n",
    "\n",
    "# Convert month numbers to readable names\n",
    "# WHY: Improves interpretability for stakeholders\n",
    "month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "monthly_avg.index = month_labels\n",
    "\n",
    "monthly_avg.plot(kind='bar', ax=ax, color='seagreen', edgecolor='black')\n",
    "ax.set_title('Average Energy Consumption by Month', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Month', fontsize=12)\n",
    "ax.set_ylabel('Average Consumption', fontsize=12)\n",
    "ax.set_xticklabels(month_labels, rotation=45)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# KEY INSIGHTS:\n",
    "# - Winter months (Dec, Jan, Feb) may show high consumption (heating)\n",
    "# - Summer months (Jun, Jul, Aug) may show high consumption (cooling)\n",
    "# - Spring/Fall may show moderate consumption\n",
    "# - This justifies our 'month' and cyclical month features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a57b840",
   "metadata": {},
   "source": [
    "## 7. Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# STEP 7: Distribution Analysis\n",
    "# ===================================================================\n",
    "# WHY: Understanding the distribution helps us:\n",
    "#      1. Identify outliers (unusually high/low consumption)\n",
    "#      2. Check for normality (important for some models)\n",
    "#      3. Detect skewness and plan transformations if needed\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# HISTOGRAM: Shows frequency distribution of consumption values\n",
    "# WHY: Reveals the shape of the distribution (normal, skewed, bimodal, etc.)\n",
    "df_clean[target_col].hist(bins=50, ax=axes[0], color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Distribution of Energy Consumption', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Energy Consumption', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# BOX PLOT: Shows quartiles, median, and outliers\n",
    "# WHY: Easily identifies outliers (points beyond whiskers)\n",
    "#      Shows the interquartile range (IQR) - where 50% of data lies\n",
    "df_clean.boxplot(column=target_col, ax=axes[1])\n",
    "axes[1].set_title('Box Plot of Energy Consumption', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Energy Consumption', fontsize=12)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display key distribution statistics\n",
    "# WHY: Quantifies the distribution characteristics\n",
    "print(f\"Mean: {df_clean[target_col].mean():.2f}\")      # Average consumption\n",
    "print(f\"Median: {df_clean[target_col].median():.2f}\")  # Middle value (robust to outliers)\n",
    "print(f\"Std Dev: {df_clean[target_col].std():.2f}\")    # Variability measure\n",
    "print(f\"Skewness: {df_clean[target_col].skew():.2f}\")  # Asymmetry measure\n",
    "# WHY: Skewness near 0 indicates symmetry (normal-like distribution)\n",
    "#      Positive skew means long right tail (high outliers)\n",
    "#      Negative skew means long left tail (low outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c239050",
   "metadata": {},
   "source": [
    "## 8. Key Insights\n",
    "\n",
    "**From the exploration:**\n",
    "\n",
    "1. **Daily Patterns:** Clear peaks during business hours (typically 9AM-6PM)\n",
    "2. **Weekly Patterns:** Weekday vs weekend differences visible\n",
    "3. **Seasonal Patterns:** Monthly variations indicate seasonal effects\n",
    "4. **Data Quality:** Minimal missing values, good temporal consistency\n",
    "\n",
    "**Modeling Strategy:**\n",
    "- Use lag features (1h, 24h, 168h) to capture temporal dependencies\n",
    "- Include time-based features (hour, day_of_week, month)\n",
    "- Add rolling statistics to smooth trends\n",
    "- Apply time-based train-test split to prevent leakage\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:** Run `main.py` for full model training and evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
